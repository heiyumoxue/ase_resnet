{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2fd1b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install tensorboard\n",
    "# !pip install tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f03d6b88",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# resnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e38b07b",
   "metadata": {},
   "source": [
    "1.Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fece2b",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1a2df71",
   "metadata": {},
   "source": [
    "ResNet, short for Residual Network, is a convolutional neural network introduced by Microsoft Research in 2015. The main innovation of ResNet is the use of residual connections, which allows the network to learn deeper architectures than traditional CNNs.\n",
    "\n",
    "A residual connection is a shortcut connection that skips one or more layers and connects the input of one layer directly to the output of a layer further down in the network. This allows the network to learn the residual mapping between the input and output of the skipped layer rather than the mapping itself.\n",
    "\n",
    "The original ResNet architecture, called ResNet-50, had 50 layers and was trained on the ImageNet dataset, achieving state-of-the-art results at the time of release. Since then, several variants of the ResNet architecture have been proposed, such as ResNet-101, ResNet-152, and ResNet-200, with more layers, and ResNet-18, with a smaller version of 18 layers.\n",
    "\n",
    "ResNet has been widely used in many computer vision tasks, such as image classification, object detection, semantic segmentation, etc. It is also a popular choice for transfer learning, where pre-trained ResNet models can be fine-tuned for different tasks with relatively small datasets.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2943f59",
   "metadata": {},
   "source": [
    "2.Detail"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fe7c9f",
   "metadata": {},
   "source": [
    "Next, I will introduce in detail what the code of each box does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37055965",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "import and add name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941e456",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from net import *\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from util import get_transform, get_acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17e65ba0",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The SummaryWriter class is used to write TensorFlow summary data to a specified directory, which can be visualized in TensorBoard. The batch size, learning rate, weight decay and number of epochs are hyperparameters that control the training process of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9aeaab",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter ('tf_logs_exp') \n",
    "batch_Size = 32\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "num_epoch = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0455a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " Define the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fa06e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model = get_resnext() \n",
    "#model = get_resnet()\n",
    "model = get_resnet18()\n",
    "\n",
    "#model = get_resnet18_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab167cb9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the name of the training weights of the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b6beb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model_path = r'model_save/resnet.pth' \n",
    "# model_path = r'model_save/resnext.pth'\n",
    "model_path = r'model_save/resnet18.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1548b6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_resnet18"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a03f3ce6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use gpu if not can use cpu.\n",
    " using a GPU with CUDA is generally better for machine learning and deep learning tasks because it allows for faster processing of large amounts of data in parallel, and it is also more versatile and easier to use than other GPU programming frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f161e28",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available () else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0daa55",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check if gpu is used correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a60bf7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = get_device ()\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b96d5",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import the correct address for train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fe8fb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to (device)\n",
    "train_path = r'dataset/train'\n",
    "val_path = r'dataset/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872623f6",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Do a transform on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d207c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transforms_train = transforms.Compose (\n",
    "#     [\n",
    "#         transforms.Resize ([224, 224]),\n",
    "#         transforms.ToTensor ()\n",
    "#     ])\n",
    "\n",
    "# transforms_vaild = transforms.Compose (\n",
    "#     [\n",
    "#         transforms.Resize ([224, 224]),\n",
    "#         transforms.ToTensor ()\n",
    "#     ])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder (root=train_path, transform=get_transform())\n",
    "val_dataset = torchvision.datasets.ImageFolder (root=val_path, transform=get_transform())\n",
    "\n",
    "print ('The dataset corresponding labels are:{}'.format (train_dataset.class_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234b20f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader (dataset=train_dataset, batch_size=batch_Size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader (dataset=val_dataset, batch_size=batch_Size, shuffle=True, num_workers=2)\n",
    "print(train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5774c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(val_loader)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322b1c9",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_images, batch_labels=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf95a29",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Image shape: {batch_images.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d701d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_name=train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae702e91",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26482000",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i in range(8):\n",
    "    plot_img=torch.tensor(data=batch_images[i].permute(1, 2, 0))\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.title(class_name[batch_labels[i]])\n",
    "    plt.imshow(plot_img)     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25bb98c",
   "metadata": {},
   "source": [
    "Define cross-entropy loss function, adam optimizer, cos cosine learning rate adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee9026",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss ()\n",
    "optimizer = torch.optim.Adam (model.parameters (), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR (optimizer, T_max=10, eta_min=0, last_epoch=-1)\n",
    "\n",
    "n_epochs = num_epoch\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33c6dff7",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfac7fd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train ()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for batch in tqdm (train_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to (device)\n",
    "        labels = labels.to (device)\n",
    "        logits = model (imgs)\n",
    "        # 计算loss\n",
    "        loss = criterion (logits, labels)\n",
    "\n",
    "        # 网络更新\n",
    "        optimizer.zero_grad ()\n",
    "        loss.backward ()\n",
    "        optimizer.step ()\n",
    "        scheduler.step ()\n",
    "\n",
    "        #if (i % 500 == 0):\n",
    "            #print (\"learning_rate:\", scheduler.get_last_lr ()[0])\n",
    "       # i = i + 1\n",
    "\n",
    "        acc = (logits.argmax (dim=-1) == labels).float ().mean ()\n",
    "\n",
    "        train_loss.append (loss.item ())\n",
    "        train_accs.append (acc.item ())\n",
    "\n",
    "    train_loss = sum (train_loss) / len (train_loss)\n",
    "    train_acc = sum (train_accs) / len (train_accs)\n",
    "\n",
    "    print (f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    train_acc_list.append (train_acc)\n",
    "    train_loss_list.append (train_loss)\n",
    "    \n",
    "\n",
    "    # 记录到tensorboard\n",
    "    writer.add_scalar ('Train Loss ', train_acc, epoch)\n",
    "    writer.add_scalar ('Train Accuracy ', train_loss, epoch)\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval ()\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for batch in tqdm (val_loader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        with torch.no_grad ():\n",
    "            logits = model (imgs.to (device))\n",
    "\n",
    "        loss = criterion (logits, labels.to (device))\n",
    "\n",
    "        acc = (logits.argmax (dim=-1) == labels.to (device)).float ().mean ()\n",
    "\n",
    "        valid_loss.append (loss.item ())\n",
    "        valid_accs.append (acc)\n",
    "\n",
    "    valid_loss = sum (valid_loss) / len (valid_loss)\n",
    "    valid_acc = sum (valid_accs) / len (valid_accs)\n",
    "\n",
    "    print (f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    valid_loss_list.append (valid_loss)\n",
    "    valid_acc_list.append (valid_acc)\n",
    "\n",
    "    # 保留在验证集上最好的模型\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save (model.state_dict (), model_path)\n",
    "        print ('saving model with acc {:.3f}'.format (best_acc))\n",
    "\n",
    "    writer.add_scalar ('Valid Loss ', valid_acc, epoch)\n",
    "    writer.add_scalar ('Valid Accuracy ', valid_loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146b8d7",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ------ Complete subplot functions in the following lines -------\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot train loss with label, title, legend\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_acc_list,label='model_0_loss')  \n",
    "plt.title('train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot test loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_loss_list,label='model_0_loss')  \n",
    "plt.title('test_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot train accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(valid_loss_list,label='model_0_acc') \n",
    "plt.title('train_acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "\n",
    "valid_accuracy_list=[]\n",
    "for i in valid_acc_list:\n",
    "    valid_accuracy_list.append(i.tolist())\n",
    "    \n",
    "# Plot test accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(valid_accuracy_list,label='model_0_acc')   \n",
    "\n",
    "plt.title('test_acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2d2b3",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_accuracy_list=[]\n",
    "for i in valid_acc_list:\n",
    "    valid_accuracy_list.append(i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d9f70",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_accuracy_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bed2edad",
   "metadata": {},
   "source": [
    "Build the model and read the trained weights. First define the model to be used, and then define the name to save the model training weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c5d75",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model = get_resnext()\n",
    "#model = get_resnet()\n",
    "model = get_resnet18()\n",
    "#model_path = r'model_save/resnet.pth'\n",
    "# model_path = r'model_save/resnext.pth'\n",
    "model_path = r'model_save/resnet18.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd52558",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_path = r'dataset/test'\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder (root=test_path, transform=get_transform())\n",
    "\n",
    "test_loader = DataLoader (dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bde671",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear (num_ftrs, 5)\n",
    "model.load_state_dict (torch.load (model_path))\n",
    "model = model.to (device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss ()\n",
    "\n",
    "model.eval ()\n",
    "test_loss = []\n",
    "test_accs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1b9b8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_acc = get_acc(model, test_loader, criterion)\n",
    "print (f\"Test  acc = {test_acc:.5f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "711e5b6b",
   "metadata": {},
   "source": [
    "Predict a single image and add a one-dimensional batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16587a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_test(model, img_path):\n",
    "    device = 'cuda'\n",
    "    data_transform = transforms.Compose ([\n",
    "        transforms.Resize ((224, 224)),\n",
    "        transforms.ToTensor (),\n",
    "    ])\n",
    "\n",
    "    img = Image.open (img_path)\n",
    "    img = data_transform (img)\n",
    "    img = torch.unsqueeze (img, dim=0)\n",
    "\n",
    "    model.eval ()\n",
    "    with torch.no_grad ():\n",
    "        output = model (img.to (device))\n",
    "        number = torch.argmax (output.to ('cpu')[0]).numpy ().item ()\n",
    "    return number\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "780522f7",
   "metadata": {},
   "source": [
    "Build the model and read the trained weights，Show the names of the predicted images as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc0fff",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = get_resnet18 ()\n",
    "    device = get_device ()\n",
    "    model.to (device)\n",
    "\n",
    "    model_path = r'model_save/resnet18.pth'\n",
    "    model.load_state_dict (torch.load (model_path))\n",
    "\n",
    "  \n",
    "    label_dict = {0:'Albedo', 1:'CC', 2:'CuChulainn', 3:'Gilgamesh', 4:'Sesshomaru'}\n",
    "    img_pre_labels=[]\n",
    "    count = 0\n",
    "    for i in os.listdir(r'prediction'):\n",
    "        img_path = r'prediction'+'/'+i\n",
    "        img_pre_label = label_dict [model_test (model, img_path)]\n",
    "        img_pre_labels.append(img_pre_label)\n",
    "\n",
    "        print ('picture {} name is： {}'.format(i,img_pre_labels[count]))\n",
    "        count+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0121d236",
   "metadata": {},
   "source": [
    "Show the names of the predicted images as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94c1dc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])    \n",
    "count1=1\n",
    "for i in os.listdir(r'prediction'):\n",
    "        custom_image = r'prediction'+'/'+ i\n",
    "        img = torchvision.io.read_image(custom_image)\n",
    "        plt.subplot(10,4,count1)\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "        plt.title(f\"Pred label: {img_pre_labels[count1-1]}\")\n",
    "        plt.axis(False)\n",
    "        count1+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9be7bf690524a001ae173d4d33bfafae108d1a5d6c5444197f0a42feb3499e60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
